summarise(n())
disa_final <- clean_disa_eid(disa_meta)
# number of sites missing datim_uid coding
disa_final %>%
filter(is.na(datim_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n())
readr::write_tsv(
disa_final,
{file_historic_output_local},
na = "")
# write_tsv NA values to ""
# check monthly submission headers
# need to update script to include new MI indicators (CD4 and Revelacao)
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(mozR)
library(glamr)
library(googlesheets4)
library(googledrive)
library(fs)
library(lubridate)
library(janitor)
library(readxl)
library(openxlsx)
library(glue)
library(gt)
load_secrets()
# paths for saving historic datasets on local drive
path_historic_imer_output_file <- "Dataout/em_imer.txt"
path_historic_prep_output_file <- "Dataout/em_prep.txt"
path_historic_dsd_output_file <- "Dataout/em_dsd.txt"
path_historic_mi_output_file <- "Dataout/em_mi.txt"
path_historic_tpt_output_file <- "Dataout/em_tpt.txt"
path_historic_txtb_output_file <- "Dataout/em_txtb.txt"
path_historic_ahd_output_file <- "Dataout/em_ahd.txt"
path_historic_ahdhiv_output_file <- "Dataout/em_ahdhiv.txt"
# path for saving historical datasets on google drive
path_historic_output_gdrive <- as_id("https://drive.google.com/drive/folders/1xBcPZNAeYGahYj_cXN5aG2-_WSDLi6rQ")
# folder where monthly submissions are stored. Update monthly!
folder_month <- "2023_12"
path_monthly_input_repo <- glue::glue("Data/Ajuda/ER_DSD_TPT_VL/{folder_month}/")
input_files <- dir({path_monthly_input_repo}, pattern = "*.xlsx")
# paths for saving monthly datasets on local drive
path_monthly_imer_output_file <- glue::glue("Dataout/IMER/monthly_processed/IMER_{folder_month}.txt")
path_monthly_prep_output_file <- glue::glue("Dataout/PrEP/monthly_processed/PREP_{folder_month}.txt")
path_monthly_dsd_output_file <- glue::glue("Dataout/DSD/monthly_processed/DSD_{folder_month}.txt")
path_monthly_mi_output_file <- glue::glue("Dataout/MI/monthly_processed/MI_{folder_month}.txt")
path_monthly_tpt_output_file <- glue::glue("Dataout/TPT/monthly_processed/TPT_{folder_month}.txt")
path_monthly_txtb_output_file <- glue::glue("Dataout/TXTB/monthly_processed/TXTB_{folder_month}.txt")
path_monthly_ahd_output_file <- glue::glue("Dataout/AHD/monthly_processed/AHD_{folder_month}.txt")
path_monthly_ahdhiv_output_file <- glue::glue("Dataout/AHD_HIV/monthly_processed/AHD_HIV_{folder_month}.txt")
# paths for saving monthly datasets on google drive
path_monthly_imer_output_gdrive <- as_id("https://drive.google.com/drive/folders/12bkLnrQNXbKpbyo-zwk9dmxS6NHDyLwU")
path_monthly_prep_output_gdrive <- as_id("https://drive.google.com/drive/folders/1BYq-xdMhxw8sOUHYwFiZH8_w2UsQmBun")
path_monthly_dsd_output_gdrive <- as_id("https://drive.google.com/drive/folders/15x2biGIIYrY_eW-zrKQbrvMT47cI5yOE")
path_monthly_mi_output_gdrive <- as_id("https://drive.google.com/drive/folders/1RC5VFhD7XkuptW7o3zd21ujY6CefcTyv")
path_monthly_tpt_output_gdrive <- as_id("https://drive.google.com/drive/folders/1JobyoQqeTP3M5VvZWMC4AMBW04nVwDeD")
path_monthly_txtb_output_gdrive <- as_id("https://drive.google.com/drive/folders/1zKg8l6bmO_6uk9GoOmxYsAWP3msHtjB3")
path_monthly_ahd_output_gdrive <- as_id("https://drive.google.com/drive/folders/1lVao3i2vP6BW41A5T52jKgPbbaOVgNKG")
path_monthly_ahdhiv_output_gdrive <- as_id("https://drive.google.com/drive/folders/18V88s6oB7bPFh3Sv4rJU_oMhJgMqXyCi")
imer_historic_files <- dir("Dataout/IMER/monthly_processed/", pattern = "*.txt")
prep_historic_files <- dir("Dataout/PrEP/monthly_processed/", pattern = "*.txt")
dsd_historic_files <- dir("Dataout/DSD/monthly_processed/", pattern = "*.txt")
mi_historic_files <- dir("Dataout/MI/monthly_processed/", pattern = "*.txt")
tpt_historic_files <- dir("Dataout/TPT/monthly_processed/", pattern = "*.txt")
tx_tb_historic_files <- dir("Dataout/TXTB/monthly_processed/", pattern = "*.txt")
ahd_historic_files <- dir("Dataout/AHD/monthly_processed/", pattern = "*.txt")
ahdhiv_historic_files <- dir("Dataout/AHD_HIV/monthly_processed/", pattern = "*.txt")
tpt_historic <- tpt_historic_files %>%
map(~ read_tsv(file.path("Dataout/TPT/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_tpt()
sims_indicator <- tpt_historic %>%
filter(indicator %in% c("TPT Completed/Active", "TX_CURR"),
period == max(period)) %>%
pivot_wider(names_from = indicator, values_from = value) %>%
group_by(period, datim_uid, snu, psnu, sitename) %>%
summarize(TX_CURR = sum(TX_CURR, na.rm = TRUE),
TPT_CUM = sum(`TPT Completed/Active`, na.rm = TRUE)) %>%
mutate(TPT_CUM_PER = TPT_CUM / TX_CURR) %>%
ungroup() %>%
select(snu,
psnu,
sitename,
orgunituid = datim_uid,
TPT_CUM_PER)
tpt_historic <- tpt_historic_files %>%
map(~ read_tsv(file.path("Dataout/TPT/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_tpt()
ajuda_site_map <- pull_sitemap()
tpt_historic <- tpt_historic_files %>%
map(~ read_tsv(file.path("Dataout/TPT/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_tpt()
sims_indicator <- tpt_historic %>%
filter(indicator %in% c("TPT Completed/Active", "TX_CURR"),
period == max(period)) %>%
pivot_wider(names_from = indicator, values_from = value) %>%
group_by(period, datim_uid, snu, psnu, sitename) %>%
summarize(TX_CURR = sum(TX_CURR, na.rm = TRUE),
TPT_CUM = sum(`TPT Completed/Active`, na.rm = TRUE)) %>%
mutate(TPT_CUM_PER = TPT_CUM / TX_CURR) %>%
ungroup() %>%
select(snu,
psnu,
sitename,
orgunituid = datim_uid,
TPT_CUM_PER)
View(sims_indicator)
readr::write_tsv(
sims_indicator,
"~/GitHub/SIMS/Data/tpt_comp.txt")
rm(list = ls())
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(fs)
library(googlesheets4)
library(googledrive)
library(glamr)
library(glitr)
library(grabr)
library(ggthemes)
library(janitor)
library(glue)
library(readxl)
library(openxlsx)
library(Wavelength)
library(mozR)
load_secrets()
# VALUES & PATHS ----------------------------------------------------------
month_input <- "2023-12-20"
file_input <- "Data/Disa_new/monthly/Relatorio Mensal de Carga Viral Dezembro 2023.xlsx"
dt <- base::format(as.Date(month_input),
"%Y_%m")
file <- glue::glue("DISA_VL_{dt}")
# paths that do not require monthly updating
path_historic_output_local <- "Dataout/DISA/monthly_processed/"
file_monthly_output_local <- path(path_historic_output_local, file, ext = "txt")
file_historic_output_local <- "Dataout/em_disa.txt"
path_monthly_output_gdrive <- as_id("https://drive.google.com/drive/folders/12XN6RKaHNlmPoy3om0cbNd1Rn4SqHSva")
path_historic_output_gdrive <- as_id("https://drive.google.com/drive/folders/1xBcPZNAeYGahYj_cXN5aG2-_WSDLi6rQ")
# DATA LOAD -------------------------------------------------------
df <- reshape_disa_vl(filepath = file_input, month = month_input)
disa_datim_map <- pull_sitemap(sheet = "map_disa") %>%
select(!c(note))
ajuda_site_map <- pull_sitemap() %>%
select(datim_uid,
partner = partner_pepfar_clinical,
starts_with("his_"))
psnuuid_map <- pull_sitemap(sheetname = "list_psnu") %>%
select(psnu,
psnuuid)
cntry <- "Mozambique"
uid <- get_ouuid(cntry)
datim_orgsuids <- pull_hierarchy(uid, username = datim_user(), password = datim_pwd()) %>%
filter(!is.na(facility) & !is.na(psnu)) %>%
select(datim_uid = orgunituid,
snu = snu1,
psnu = community, # changed to community with update to datim
sitename = facility) %>%
arrange(snu, psnu, sitename)
# datim_orgsuids_2 <- datim_orgsuids %>%
#   filter(!is.na(facility) & !is.na(psnu)) %>%
#   select(datim_uid = orgunituid,
#          snu = snu1,
#          psnuuid,
#          psnu = community, # changed to community with update to datim
#          sitename = facility)
#
# write_csv(datim_orgsuids_2,
#           "Documents/datim_uids.csv")
# SUBMISSION CHECKS -------------------------------------------------------
# tabulate unique sites that have viral load results reported
df %>%
filter(!is.na(disa_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n()) %>%
arrange(`n()`)
# tabulate sites missing disa unique identifiers
df %>%
filter(is.na(disa_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n()) %>%
arrange(`n()`)
# PRINT MONTHLY OUTPUT ----------------------------------------------------
readr::write_tsv(
df,
{file_monthly_output_local},
na ="")
historic_files <- dir({path_historic_output_local}, pattern = "*.txt")  # PATH FOR PURR TO FIND MONTHLY FILES TO COMPILE
disa_temp <- historic_files %>%
map(~ read_tsv(file.path(path_historic_output_local, .))) %>%
reduce(rbind)
# JOIN DISA MAPPING & CHECK -------------------------------------------------------
disa_meta <- disa_temp %>%
select(!site_nid) %>%
left_join(disa_datim_map, by = c("disa_uid" = "disa_uid")) %>%
mutate(ajuda = replace_na(ajuda, 0)) %>%
relocate(c(ajuda, sisma_uid, datim_uid), .before = disa_uid)
# number of sites missing datim_uid coding
disa_meta %>%
filter(is.na(datim_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n())
# REMOVE ROWS WITHOUT DATIM UID & CLEAN -----------------------------------
disa_final <- clean_disa_vl(disa_meta)
# CHECK UNIQUE AGE/SEX & ASSESS MISSING DATA --------------------------
disa_final %>%
distinct(age)
disa_final %>%
distinct(sex)
disa_missing <- disa_meta %>%
filter(is.na(datim_uid),
group == "Age") %>%
group_by(period, snu, psnu, sitename, disa_uid) %>%
summarize(
across(c(VL, VLS, TAT), .fns = sum), .groups = "drop")
check_total_vl <- sum(disa_final$VL, na.rm = T)
check_total_missing <- sum(disa_missing$VL, na.rm = T)
1 - check_total_missing / check_total_vl
disa_final %>%
filter(period > max(period) - months(6)) %>%
group_by(period, snu) %>%
distinct(period, sitename) %>%
summarise(n()) %>%
arrange(snu) %>%
print(n=100)
# PLOT HISTORIC DATA ----------------------------------------------
df_vl_plot <- disa_final %>%
filter(!is.na(group)) %>%
group_by(period, group, partner, snu) %>%
summarize(VL = sum(VL, na.rm = T)) %>%
ungroup()
df_vl_plot %>%
ggplot(aes(x = period, y = VL, fill = snu)) +
geom_col() +
labs(title = "Testing of Viral Load Specimens by Population",
subtitle = "Historical trend of Viral Load specimens processed within the DISA laboratory network",
color = "Partner") +
theme_solarized() +
theme(axis.title = element_text()) +
facet_wrap(~group)
# PRINT HISTORIC OUTPUTS ------------------------------------------------------
write.xlsx(disa_missing,
{"Dataout/DISA/missing_sites_mfl.xlsx"},
overwrite = TRUE)
readr::write_tsv(
disa_final,
{file_historic_output_local},
na = "")
drive_put(file_historic_output_local,
path = path_historic_output_gdrive)
# write_tsv NA values to ""
# check monthly submission headers
# need to update script to include new MI indicators (CD4 and Revelacao)
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(mozR)
library(glamr)
library(googlesheets4)
library(googledrive)
library(fs)
library(lubridate)
library(janitor)
library(readxl)
library(openxlsx)
library(glue)
library(gt)
load_secrets()
# GLOBAL VARIABLES ---------------------------------------------------------------
# folder where monthly submissions are stored. Update monthly!
folder_month <- "2024_01"
path_monthly_input_repo <- glue::glue("Data/Ajuda/ER_DSD_TPT_VL/{folder_month}/")
input_files <- dir({path_monthly_input_repo}, pattern = "*.xlsx")
# paths for saving monthly datasets on local drive
path_monthly_imer_output_file <- glue::glue("Dataout/IMER/monthly_processed/IMER_{folder_month}.txt")
path_monthly_prep_output_file <- glue::glue("Dataout/PrEP/monthly_processed/PREP_{folder_month}.txt")
path_monthly_dsd_output_file <- glue::glue("Dataout/DSD/monthly_processed/DSD_{folder_month}.txt")
path_monthly_mi_output_file <- glue::glue("Dataout/MI/monthly_processed/MI_{folder_month}.txt")
path_monthly_tpt_output_file <- glue::glue("Dataout/TPT/monthly_processed/TPT_{folder_month}.txt")
path_monthly_txtb_output_file <- glue::glue("Dataout/TXTB/monthly_processed/TXTB_{folder_month}.txt")
path_monthly_ahd_output_file <- glue::glue("Dataout/AHD/monthly_processed/AHD_{folder_month}.txt")
path_monthly_ahdhiv_output_file <- glue::glue("Dataout/AHD_HIV/monthly_processed/AHD_HIV_{folder_month}.txt")
# paths for saving monthly datasets on google drive
path_monthly_imer_output_gdrive <- as_id("https://drive.google.com/drive/folders/12bkLnrQNXbKpbyo-zwk9dmxS6NHDyLwU")
path_monthly_prep_output_gdrive <- as_id("https://drive.google.com/drive/folders/1BYq-xdMhxw8sOUHYwFiZH8_w2UsQmBun")
path_monthly_dsd_output_gdrive <- as_id("https://drive.google.com/drive/folders/15x2biGIIYrY_eW-zrKQbrvMT47cI5yOE")
path_monthly_mi_output_gdrive <- as_id("https://drive.google.com/drive/folders/1RC5VFhD7XkuptW7o3zd21ujY6CefcTyv")
path_monthly_tpt_output_gdrive <- as_id("https://drive.google.com/drive/folders/1JobyoQqeTP3M5VvZWMC4AMBW04nVwDeD")
path_monthly_txtb_output_gdrive <- as_id("https://drive.google.com/drive/folders/1zKg8l6bmO_6uk9GoOmxYsAWP3msHtjB3")
path_monthly_ahd_output_gdrive <- as_id("https://drive.google.com/drive/folders/1lVao3i2vP6BW41A5T52jKgPbbaOVgNKG")
path_monthly_ahdhiv_output_gdrive <- as_id("https://drive.google.com/drive/folders/18V88s6oB7bPFh3Sv4rJU_oMhJgMqXyCi")
# paths for saving historic datasets on local drive
path_historic_imer_output_file <- "Dataout/em_imer.txt"
path_historic_prep_output_file <- "Dataout/em_prep.txt"
path_historic_dsd_output_file <- "Dataout/em_dsd.txt"
path_historic_mi_output_file <- "Dataout/em_mi.txt"
path_historic_tpt_output_file <- "Dataout/em_tpt.txt"
path_historic_txtb_output_file <- "Dataout/em_txtb.txt"
path_historic_ahd_output_file <- "Dataout/em_ahd.txt"
path_historic_ahdhiv_output_file <- "Dataout/em_ahdhiv.txt"
# path for saving historical datasets on google drive
path_historic_output_gdrive <- as_id("https://drive.google.com/drive/folders/1xBcPZNAeYGahYj_cXN5aG2-_WSDLi6rQ")
# 1. LOAD SITE META DATA ---------------------------------------------------------------
ajuda_site_map <- pull_sitemap()
imer_historic_files <- dir("Dataout/IMER/monthly_processed/", pattern = "*.txt")
prep_historic_files <- dir("Dataout/PrEP/monthly_processed/", pattern = "*.txt")
dsd_historic_files <- dir("Dataout/DSD/monthly_processed/", pattern = "*.txt")
mi_historic_files <- dir("Dataout/MI/monthly_processed/", pattern = "*.txt")
tpt_historic_files <- dir("Dataout/TPT/monthly_processed/", pattern = "*.txt")
tx_tb_historic_files <- dir("Dataout/TXTB/monthly_processed/", pattern = "*.txt")
ahd_historic_files <- dir("Dataout/AHD/monthly_processed/", pattern = "*.txt")
ahdhiv_historic_files <- dir("Dataout/AHD_HIV/monthly_processed/", pattern = "*.txt")
imer_historic <- imer_historic_files %>%
map(~ read_tsv(file.path("Dataout/IMER/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_imer()
prep_historic <- prep_historic_files %>%
map(~ read_tsv(file.path("Dataout/PrEP/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_prep()
dsd_historic <- dsd_historic_files %>%
map(~ read_tsv(file.path("Dataout/DSD/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_dsd()
mi_historic <- mi_historic_files %>%
map(~ read_tsv(file.path("Dataout/MI/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_mi()
tpt_historic <- tpt_historic_files %>%
map(~ read_tsv(file.path("Dataout/TPT/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_tpt()
txtb_historic <- tx_tb_historic_files %>%
map(~ read_tsv(file.path("Dataout/TXTB/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_txtb()
ahd_historic <- ahd_historic_files %>%
map(~ read_tsv(file.path("Dataout/AHD/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_ahd() %>%
filter(value > 0) # consider putting in the monthly
ahdhiv_historic <- ahdhiv_historic_files %>%
map(~ read_tsv(file.path("Dataout/AHD_HIV/monthly_processed/", .))) %>%
reduce(rbind) %>%
clean_em_ahdhiv()
# 3.2 REVIEW HISTORICAL DATASETS ------------------------------------------------------------
imer_historic %>%
filter(is.na(datim_uid)) %>%
distinct(datim_uid, snu, psnu, sitename, period)
prep_historic %>%
filter(is.na(datim_uid)) %>%
distinct(datim_uid, snu, psnu, sitename, period)
dsd_historic %>%
filter(is.na(datim_uid)) %>%
distinct(datim_uid, snu, psnu, sitename, period)
mi_historic %>%
filter(is.na(datim_uid)) %>%
distinct(datim_uid, snu, psnu, sitename, period)
tpt_historic %>%
filter(is.na(datim_uid)) %>%
distinct(datim_uid, snu, psnu, sitename, period)
txtb_historic %>%
filter(is.na(datim_uid)) %>%
distinct(datim_uid, snu, psnu, sitename, period)
ahd_historic %>%
filter(is.na(datim_uid)) %>%
distinct(datim_uid, snu, psnu, sitename, period)
ahdhiv_historic %>%
filter(is.na(datim_uid)) %>%
distinct(datim_uid, snu, psnu, sitename, period)
plot_em_imer(imer_historic)
plot_em_prep(prep_historic)
plot_em_dsd(dsd_historic)
plot_em_mi(mi_historic)
plot_em_tpt(tpt_historic)
plot_em_txtb(txtb_historic)
# 3.3 REMOVE DATIM_UID NA DATA LINES --------------------------------------
imer_historic <- imer_historic %>%
filter(!is.na(datim_uid))
prep_historic <- prep_historic %>%
filter(!is.na(datim_uid))
dsd_historic <- dsd_historic %>%
filter(!is.na(datim_uid))
mi_historic <- mi_historic %>%
filter(!is.na(datim_uid))
tpt_historic <- tpt_historic %>%
filter(!is.na(datim_uid))
txtb_historic <- txtb_historic %>%
filter(!is.na(datim_uid))
ahd_historic <- ahd_historic %>%
filter(!is.na(datim_uid))
ahdhiv_historic <- ahdhiv_historic %>%
filter(!is.na(datim_uid))
# 3.4 WRITE HISTORIC TO LOCAL DRIVE --------------------------------------------------
readr::write_tsv(
imer_historic,
path_historic_imer_output_file)
readr::write_tsv(
prep_historic,
path_historic_prep_output_file)
readr::write_tsv(
dsd_historic,
path_historic_dsd_output_file)
readr::write_tsv(
mi_historic,
path_historic_mi_output_file)
readr::write_tsv(
mi_historic,
path_historic_mi_output_file,
na = "")
readr::write_tsv(
tpt_historic,
path_historic_tpt_output_file)
readr::write_tsv(
txtb_historic,
path_historic_txtb_output_file)
readr::write_tsv(
ahd_historic,
path_historic_ahd_output_file)
readr::write_tsv(
ahdhiv_historic,
path_historic_ahdhiv_output_file)
# prep
drive_put(path_historic_prep_output_file,
path = path_historic_output_gdrive)
# dsd
drive_put(path_historic_dsd_output_file,
path = path_historic_output_gdrive)
# write_tsv NA values to ""
# check monthly submission headers
# need to update script to include new MI indicators (CD4 and Revelacao)
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(mozR)
library(glamr)
library(googlesheets4)
library(googledrive)
library(fs)
library(lubridate)
library(janitor)
library(readxl)
library(openxlsx)
library(glue)
library(gt)
load_secrets()
# GLOBAL VARIABLES ---------------------------------------------------------------
# folder where monthly submissions are stored. Update monthly!
folder_month <- "2024_01"
path_monthly_input_repo <- glue::glue("Data/Ajuda/ER_DSD_TPT_VL/{folder_month}/")
input_files <- dir({path_monthly_input_repo}, pattern = "*.xlsx")
# paths for saving monthly datasets on local drive
path_monthly_imer_output_file <- glue::glue("Dataout/IMER/monthly_processed/IMER_{folder_month}.txt")
path_monthly_prep_output_file <- glue::glue("Dataout/PrEP/monthly_processed/PREP_{folder_month}.txt")
path_monthly_dsd_output_file <- glue::glue("Dataout/DSD/monthly_processed/DSD_{folder_month}.txt")
path_monthly_mi_output_file <- glue::glue("Dataout/MI/monthly_processed/MI_{folder_month}.txt")
path_monthly_tpt_output_file <- glue::glue("Dataout/TPT/monthly_processed/TPT_{folder_month}.txt")
path_monthly_txtb_output_file <- glue::glue("Dataout/TXTB/monthly_processed/TXTB_{folder_month}.txt")
path_monthly_ahd_output_file <- glue::glue("Dataout/AHD/monthly_processed/AHD_{folder_month}.txt")
path_monthly_ahdhiv_output_file <- glue::glue("Dataout/AHD_HIV/monthly_processed/AHD_HIV_{folder_month}.txt")
# paths for saving monthly datasets on google drive
path_monthly_imer_output_gdrive <- as_id("https://drive.google.com/drive/folders/12bkLnrQNXbKpbyo-zwk9dmxS6NHDyLwU")
path_monthly_prep_output_gdrive <- as_id("https://drive.google.com/drive/folders/1BYq-xdMhxw8sOUHYwFiZH8_w2UsQmBun")
path_monthly_dsd_output_gdrive <- as_id("https://drive.google.com/drive/folders/15x2biGIIYrY_eW-zrKQbrvMT47cI5yOE")
path_monthly_mi_output_gdrive <- as_id("https://drive.google.com/drive/folders/1RC5VFhD7XkuptW7o3zd21ujY6CefcTyv")
path_monthly_tpt_output_gdrive <- as_id("https://drive.google.com/drive/folders/1JobyoQqeTP3M5VvZWMC4AMBW04nVwDeD")
path_monthly_txtb_output_gdrive <- as_id("https://drive.google.com/drive/folders/1zKg8l6bmO_6uk9GoOmxYsAWP3msHtjB3")
path_monthly_ahd_output_gdrive <- as_id("https://drive.google.com/drive/folders/1lVao3i2vP6BW41A5T52jKgPbbaOVgNKG")
path_monthly_ahdhiv_output_gdrive <- as_id("https://drive.google.com/drive/folders/18V88s6oB7bPFh3Sv4rJU_oMhJgMqXyCi")
# paths for saving historic datasets on local drive
path_historic_imer_output_file <- "Dataout/em_imer.txt"
path_historic_prep_output_file <- "Dataout/em_prep.txt"
path_historic_dsd_output_file <- "Dataout/em_dsd.txt"
path_historic_mi_output_file <- "Dataout/em_mi.txt"
path_historic_tpt_output_file <- "Dataout/em_tpt.txt"
path_historic_txtb_output_file <- "Dataout/em_txtb.txt"
path_historic_ahd_output_file <- "Dataout/em_ahd.txt"
path_historic_ahdhiv_output_file <- "Dataout/em_ahdhiv.txt"
# path for saving historical datasets on google drive
path_historic_output_gdrive <- as_id("https://drive.google.com/drive/folders/1xBcPZNAeYGahYj_cXN5aG2-_WSDLi6rQ")
# 1. LOAD SITE META DATA ---------------------------------------------------------------
ajuda_site_map <- pull_sitemap()
# ahdhiv
drive_put(path_historic_ahdhiv_output_file,
path = path_historic_output_gdrive)
# ahd
drive_put(path_historic_ahd_output_file,
path = path_historic_output_gdrive)
# tpt
drive_put(path_historic_tpt_output_file,
path = path_historic_output_gdrive)
# txtb
drive_put(path_historic_txtb_output_file,
path = path_historic_output_gdrive)
# imer
drive_put(path_historic_imer_output_file,
path = path_historic_output_gdrive)
# prep
drive_put(path_historic_prep_output_file,
path = path_historic_output_gdrive)
# dsd
drive_put(path_historic_dsd_output_file,
path = path_historic_output_gdrive)
# mi
drive_put(path_historic_mi_output_file,
path = path_historic_output_gdrive)
