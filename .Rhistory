stringr::str_detect(tat_step, "s1.") ~ "P1: Colheita a Disa-Link",
stringr::str_detect(tat_step, "s2.") ~ "P2: Disa-Link a Laboratorio",
stringr::str_detect(tat_step, "s3.") ~ "P3: Laboratorio a Registo",
stringr::str_detect(tat_step, "s4.") ~ "P4: Registo a Analise",
stringr::str_detect(tat_step, "s5.") ~ "P5: Analise a Validacao",
TRUE ~ tat_step),
disagregacao_sub = disa_uid) %>%
dplyr::filter(!tat_step == "total")
# bind dataframes
df <- dplyr::bind_rows(dpi, dpi_pos, df_tat) %>%
dplyr::select(!c(snu, psnu, sitename, sex, tat_step)) |>
dplyr::mutate(
periodo_coorte = NA_character_,
fonte = "DISA",
sub_grupo = NA_character_,
idade = NA_character_,
idade_agrupada = NA_character_
)
# fetch site maps for recoding site metadata
map_disa <- mozR::pull_sitemap(sheetname = "map_disa") |> dplyr::select(!c("note", "ajuda", "site_nid", "datim_uid"))
map_ou <- mozR::pull_sitemap(sheetname = "list_sisma") |> dplyr::select(c("sisma_uid", "provincia", "distrito", "us"))
df_1 <- df |>
dplyr::left_join(map_disa, dplyr::join_by(disa_uid)) |>
dplyr::left_join(map_ou, dplyr::join_by(sisma_uid)) |>
dplyr::select(!disa_uid) |>
dplyr::select(sisma_uid,
provincia,
distrito,
us,
periodo,
periodo_coorte,
indicador,
fonte,
disagregacao,
disagregacao_sub,
sub_grupo,
sexo,
idade,
idade_agrupada,
resultado_estado,
valor)
return(df_1)
}
df <- process_disa_dpi(filename = file_input, month = month_input)
View(df)
rm(list = ls())
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(fs)
library(googlesheets4)
library(googledrive)
library(glamr)
library(glitr)
library(grabr)
library(ggthemes)
library(janitor)
library(glue)
library(readxl)
library(openxlsx)
library(Wavelength)
library(mozR)
load_secrets()
install.packages('glamr', repos = c('https://usaid-oha-si.r-universe.dev', 'https://cloud.r-project.org'))
install.packages("glamr", repos = c("https://usaid-oha-si.r-universe.dev", "https://cloud.r-project.org"))
install.packages('glitr', repos = c('https://usaid-oha-si.r-universe.dev', 'https://cloud.r-project.org'))
rm(list = ls())
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(fs)
library(googlesheets4)
library(googledrive)
library(glamr)
library(glitr)
library(grabr)
library(ggthemes)
library(janitor)
library(glue)
library(readxl)
library(openxlsx)
library(Wavelength)
library(mozR)
load_secrets()
rm(list = ls())
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(fs)
library(googlesheets4)
library(googledrive)
library(glamr)
library(glitr)
library(grabr)
library(ggthemes)
library(janitor)
library(glue)
library(readxl)
library(openxlsx)
library(Wavelength)
library(mozR)
load_secrets()
# VALUES & PATHS ----------------------------------------------------------
month_input <- "2024-06-20"
file_input <- "Data/Disa_new/monthly/Relatorio Mensal de Carga Viral Junho 2024.xlsx"
dt <- base::format(as.Date(month_input),
"%Y_%m")
file <- glue::glue("DISA_VL_{dt}")
# paths that do not require monthly updating
path_historic_output_local <- "Dataout/DISA/monthly_processed/"
file_monthly_output_local <- path(path_historic_output_local, file, ext = "txt")
file_historic_output_local <- "Dataout/em_disa.txt"
path_monthly_output_gdrive <- as_id("https://drive.google.com/drive/folders/12XN6RKaHNlmPoy3om0cbNd1Rn4SqHSva")
path_historic_output_gdrive <- as_id("https://drive.google.com/drive/folders/1xBcPZNAeYGahYj_cXN5aG2-_WSDLi6rQ")
df <- reshape_disa_vl(filepath = file_input, month = month_input)
disa_datim_map <- pull_sitemap(sheet = "map_disa") %>%
select(!c(note))
ajuda_site_map <- pull_sitemap() %>%
select(datim_uid,
partner = partner_pepfar_clinical,
starts_with("his_"))
psnuuid_map <- pull_sitemap(sheetname = "list_psnu") %>%
select(psnu,
psnuuid)
cntry <- "Mozambique"
uid <- get_ouuid(cntry)
datim_orgsuids <- pull_hierarchy(uid, username = datim_user(), password = datim_pwd()) %>%
filter(!is.na(facility) & !is.na(psnu)) %>%
select(datim_uid = orgunituid,
snu = snu1,
psnu = community, # changed to community with update to datim
sitename = facility) %>%
arrange(snu, psnu, sitename)
# tabulate unique sites that have viral load results reported
df %>%
filter(!is.na(disa_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n()) %>%
arrange(`n()`)
# tabulate sites missing disa unique identifiers
df %>%
filter(is.na(disa_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n()) %>%
arrange(`n()`)
# PRINT MONTHLY OUTPUT ----------------------------------------------------
readr::write_tsv(
df,
{file_monthly_output_local},
na ="")
drive_put(file_monthly_output_local,
path = path_monthly_output_gdrive,
name = glue({file}, '.txt')
)
historic_files <- dir({path_historic_output_local}, pattern = "*.txt")  # PATH FOR PURR TO FIND MONTHLY FILES TO COMPILE
disa_temp <- historic_files %>%
map(~ read_tsv(file.path(path_historic_output_local, .))) %>%
reduce(rbind)
disa_meta <- disa_temp %>%
select(!site_nid) %>%
left_join(disa_datim_map, by = c("disa_uid" = "disa_uid")) %>%
mutate(ajuda = replace_na(ajuda, 0)) %>%
relocate(c(ajuda, sisma_uid, datim_uid), .before = disa_uid)
# number of sites missing datim_uid coding
disa_meta %>%
filter(is.na(datim_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n())
# REMOVE ROWS WITHOUT DATIM UID & CLEAN -----------------------------------
disa_final <- clean_disa_vl(disa_meta)
disa_final %>%
distinct(age)
disa_final %>%
distinct(sex)
disa_missing <- disa_meta %>%
filter(is.na(datim_uid),
group == "Age") %>%
group_by(period, snu, psnu, sitename, disa_uid) %>%
summarize(
across(c(VL, VLS, TAT), .fns = sum), .groups = "drop")
check_total_vl <- sum(disa_final$VL, na.rm = T)
check_total_missing <- sum(disa_missing$VL, na.rm = T)
1 - check_total_missing / check_total_vl
disa_final %>%
filter(period > max(period) - months(6)) %>%
group_by(period, snu) %>%
distinct(period, sitename) %>%
summarise(n()) %>%
arrange(snu) %>%
print(n=100)
df_vl_plot <- disa_final %>%
filter(!is.na(group)) %>%
group_by(period, group, partner, snu) %>%
summarize(VL = sum(VL, na.rm = T)) %>%
ungroup()
df_vl_plot %>%
ggplot(aes(x = period, y = VL, fill = snu)) +
geom_col() +
labs(title = "Testing of Viral Load Specimens by Population",
subtitle = "Historical trend of Viral Load specimens processed within the DISA laboratory network",
color = "Partner") +
theme_solarized() +
theme(axis.title = element_text()) +
facet_wrap(~group)
write.xlsx(disa_missing,
{"Dataout/DISA/missing_sites_mfl.xlsx"},
overwrite = TRUE)
readr::write_tsv(
disa_final,
{file_historic_output_local},
na = "")
drive_put(file_historic_output_local,
path = path_historic_output_gdrive)
rm(list = ls())
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(fs)
library(googlesheets4)
library(googledrive)
library(glamr)
library(glitr)
library(grabr)
library(ggthemes)
library(janitor)
library(glue)
library(readxl)
library(openxlsx)
library(Wavelength)
library(mozR)
load_secrets()
# PATHS & VALUES --------------------------------
month_input <- "2024-06-20"
file_input <- "Data/Disa_new/monthly/Relatorio Mensal de DPI Junho 2024.xlsx"
dt <- base::format(as.Date(month_input),
"%Y_%m")
file <- glue::glue("DISA_DPI_{dt}")
# paths that do not require monthly updating
path_historic_output_local <- "Dataout/DISA/dpi_monthly_processed/"
file_monthly_output_local <- path(path_historic_output_local, file, ext = "txt")
file_historic_output_local <- "Dataout/em_dpi.txt"
path_monthly_output_gdrive <- as_id("https://drive.google.com/drive/folders/1dYjLGeGQVZEXlFcDInx5_1YTtnFPN0gM")
path_historic_output_gdrive <- as_id("https://drive.google.com/drive/folders/1xBcPZNAeYGahYj_cXN5aG2-_WSDLi6rQ")
# LOAD DATA ----------------------------
df <- reshape_disa_dpi(filename = file_input, month = month_input)
disa_datim_map <- pull_sitemap(sheet = "map_disa") %>%
select(!c(note))
ajuda_site_map <- pull_sitemap() %>%
select(datim_uid,
partner = partner_pepfar_clinical,
starts_with("his_"))
psnuuid_map <- pull_sitemap(sheetname = "list_psnu") %>%
select(psnu,
psnuuid)
cntry <- "Mozambique"
uid <- get_ouuid(cntry)
datim_orgsuids <- pull_hierarchy(uid, username = datim_user(), password = datim_pwd()) %>%
filter(!is.na(facility) & !is.na(psnu)) %>%
select(datim_uid = orgunituid,
snu = snu1,
psnu = community, # changed to community with update to datim
sitename = facility) %>%
arrange(snu, psnu, sitename)
datim_orgsuids <- read_csv("Documents/datim_uids.csv") |>
arrange(snu, psnu, sitename)
# tabulate unique sites that have viral load results reported
df %>%
filter(!is.na(disa_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n()) %>%
arrange(`n()`)
# tabulate sites missing disa unique identifiers
df %>%
filter(is.na(disa_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n()) %>%
arrange(`n()`)
readr::write_tsv(
df,
{file_monthly_output_local},
na ="")
drive_put(file_monthly_output_local,
path = path_monthly_output_gdrive,
name = glue({file}, '.txt')
)
historic_files <- dir({path_historic_output_local}, pattern = "*.txt")  # PATH FOR PURR TO FIND MONTHLY FILES TO COMPILE
disa_temp <- historic_files %>%
map(~ read_tsv(file.path(path_historic_output_local, .))) %>%
reduce(rbind)
disa_meta <- disa_temp %>%
left_join(disa_datim_map, by = c("disa_uid" = "disa_uid"), multiple = "first") %>% # two additional lines of data being introduced with left join
mutate(ajuda = replace_na(ajuda, 0)) %>%
relocate(c(ajuda, sisma_uid, datim_uid), .before = disa_uid)
# number of sites missing datim_uid coding
disa_meta %>%
filter(is.na(datim_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n())
disa_final <- clean_disa_eid(disa_meta)
disa_final <- disa_meta %>%
tidyr::drop_na(datim_uid) %>%
dplyr::select(!c(snu, psnu, sitename)) %>%
dplyr::left_join(datim_orgsuids, by = "datim_uid") %>%
dplyr::left_join(ajuda_site_map, by = "datim_uid") %>%
# dplyr::left_join(psnuuid_map, by = "psnu") %>%
# select(!psnuuid.y) |>
# rename(psnuuid = psnuuid.x) |>
dplyr::mutate(
partner = tidyr::replace_na(partner, "MISAU"),
support_type = dplyr::case_when(
partner == "MISAU" ~ "Sustainability",
TRUE ~ as.character("AJUDA")),
agency = dplyr::case_when(
partner == "MISAU" ~ "MISAU",
partner == "JHPIEGO-DoD" ~ "DOD",
partner == "ECHO" ~ "USAID",
TRUE ~ as.character("HHS/CDC")),
psnuuid = dplyr::case_when(
partner == "JHPIEGO-DoD" ~ "siMZUtd2cJW",
TRUE ~ psnuuid),
dplyr::across(c(snu, psnu, sitename), ~ dplyr::case_when(partner == "JHPIEGO-DoD" ~ "_Military",
TRUE ~ .))) %>%
dplyr::select(period,
sisma_uid,
datim_uid,
disa_uid,
site_nid,
ajuda,
starts_with("his_"),
snu,
psnu,
psnuuid,
sitename,
support_type,
partner,
agency,
sex,
disaggregate,
result,
tat_step,
indicator,
value)
# number of sites missing datim_uid coding
disa_final %>%
filter(is.na(datim_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n())
readr::write_tsv(
disa_final,
{file_historic_output_local},
na = "")
drive_put(file_historic_output_local,
path = path_historic_output_gdrive)
rm(list = ls())
# DEPENDENCIES ------------------------------------------------------------
library(tidyverse)
library(fs)
library(googlesheets4)
library(googledrive)
library(glamr)
library(glitr)
library(grabr)
library(ggthemes)
library(janitor)
library(glue)
library(readxl)
library(openxlsx)
library(Wavelength)
library(mozR)
load_secrets()
month_input <- "2024-06-20"
file_input <- "Data/Disa_new/monthly/Relatorio Mensal de Carga Viral Junho 2024.xlsx"
dt <- base::format(as.Date(month_input),
"%Y_%m")
file <- glue::glue("DISA_VL_{dt}")
# paths that do not require monthly updating
path_historic_output_local <- "Dataout/DISA/monthly_processed/"
file_monthly_output_local <- path(path_historic_output_local, file, ext = "txt")
file_historic_output_local <- "Dataout/em_disa.txt"
path_monthly_output_gdrive <- as_id("https://drive.google.com/drive/folders/12XN6RKaHNlmPoy3om0cbNd1Rn4SqHSva")
path_historic_output_gdrive <- as_id("https://drive.google.com/drive/folders/1xBcPZNAeYGahYj_cXN5aG2-_WSDLi6rQ")
df <- reshape_disa_vl(filepath = file_input, month = month_input)
View(df)
disa_datim_map <- pull_sitemap(sheet = "map_disa") %>%
select(!c(note))
View(disa_datim_map)
ajuda_site_map <- pull_sitemap() %>%
select(datim_uid,
partner = partner_pepfar_clinical,
starts_with("his_"))
psnuuid_map <- pull_sitemap(sheetname = "list_psnu") %>%
select(psnu,
psnuuid)
View(psnuuid_map)
cntry <- "Mozambique"
uid <- get_ouuid(cntry)
datim_orgsuids <- pull_hierarchy(uid, username = datim_user(), password = datim_pwd()) %>%
filter(!is.na(facility) & !is.na(psnu)) %>%
select(datim_uid = orgunituid,
snu = snu1,
psnu = community, # changed to community with update to datim
sitename = facility) %>%
arrange(snu, psnu, sitename)
cntry <- "Mozambique"
uid <- get_ouuid(cntry)
rm(uid)
uid <- get_ouuid(cntry)
datim_orgsuids <- pull_hierarchy(uid, username = datim_user(), password = datim_pwd()) %>%
filter(!is.na(facility) & !is.na(psnu)) %>%
select(datim_uid = orgunituid,
snu = snu1,
psnu = community, # changed to community with update to datim
sitename = facility) %>%
arrange(snu, psnu, sitename)
View(datim_orgsuids)
# tabulate unique sites that have viral load results reported
df %>%
filter(!is.na(disa_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n()) %>%
arrange(`n()`)
# tabulate sites missing disa unique identifiers
df %>%
filter(is.na(disa_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n()) %>%
arrange(`n()`)
readr::write_tsv(
df,
{file_monthly_output_local},
na ="")
drive_put(file_monthly_output_local,
path = path_monthly_output_gdrive,
name = glue({file}, '.txt')
)
historic_files <- dir({path_historic_output_local}, pattern = "*.txt")  # PATH FOR PURR TO FIND MONTHLY FILES TO COMPILE
disa_temp <- historic_files %>%
map(~ read_tsv(file.path(path_historic_output_local, .))) %>%
reduce(rbind)
disa_temp <- historic_files %>%
map(~ read_tsv(file.path(path_historic_output_local, .))) %>%
reduce(rbind)
disa_meta <- disa_temp %>%
select(!site_nid) %>%
left_join(disa_datim_map, by = c("disa_uid" = "disa_uid")) %>%
mutate(ajuda = replace_na(ajuda, 0)) %>%
relocate(c(ajuda, sisma_uid, datim_uid), .before = disa_uid)
View(disa_meta)
# number of sites missing datim_uid coding
disa_meta %>%
filter(is.na(datim_uid)) %>%
group_by(snu) %>%
distinct(sitename) %>%
summarise(n())
clean_disa_vl
disa_final <- clean_disa_vl(disa_meta)
View(disa_final)
disa_final %>%
distinct(age)
disa_final %>%
distinct(sex)
disa_missing <- disa_meta %>%
filter(is.na(datim_uid),
group == "Age") %>%
group_by(period, snu, psnu, sitename, disa_uid) %>%
summarize(
across(c(VL, VLS, TAT), .fns = sum), .groups = "drop")
check_total_vl <- sum(disa_final$VL, na.rm = T)
check_total_missing <- sum(disa_missing$VL, na.rm = T)
1 - check_total_missing / check_total_vl
disa_missing <- disa_meta %>%
filter(is.na(datim_uid),
group == "Age") %>%
group_by(period, snu, psnu, sitename, disa_uid) %>%
summarize(
across(c(VL, VLS, TAT), .fns = sum), .groups = "drop")
check_total_vl <- sum(disa_final$VL, na.rm = T)
check_total_missing <- sum(disa_missing$VL, na.rm = T)
1 - check_total_missing / check_total_vl
disa_final %>%
filter(period > max(period) - months(6)) %>%
group_by(period, snu) %>%
distinct(period, sitename) %>%
summarise(n()) %>%
arrange(snu) %>%
print(n=100)
df_vl_plot <- disa_final %>%
filter(!is.na(group)) %>%
group_by(period, group, partner, snu) %>%
summarize(VL = sum(VL, na.rm = T)) %>%
ungroup()
df_vl_plot %>%
ggplot(aes(x = period, y = VL, fill = snu)) +
geom_col() +
labs(title = "Testing of Viral Load Specimens by Population",
subtitle = "Historical trend of Viral Load specimens processed within the DISA laboratory network",
color = "Partner") +
theme_solarized() +
theme(axis.title = element_text()) +
facet_wrap(~group)
write.xlsx(disa_missing,
{"Dataout/DISA/missing_sites_mfl.xlsx"},
overwrite = TRUE)
readr::write_tsv(
disa_final,
{file_historic_output_local},
na = "")
